{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dab6e08-0b90-41e4-bc52-b5df581316da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports.TactileDataset import TactileDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6970713b-02db-408f-a6f9-fb98cb1ba67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TactileDataset(407)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = TactileDataset(root=\"/home/hussain/tactile/data/contact_extraction2/train/\")\n",
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d803b5-5efc-48fc-b5c0-f088486938c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43msamples\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'samples' is not defined"
     ]
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f7486-6405-4efb-8f9d-11908ca4aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = [v['case'] for k,v in samples.items()]\n",
    "n_ev = [len(v['events']) for k,v in samples.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e99e3fd-620b-4867-824d-d3864a8e50eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_raw(root):\n",
    "    samples = {}\n",
    "    for subset in ['train', 'val', 'test']:\n",
    "        with open(root / subset / 'raw' / 'contact_cases.json', 'r') as f:\n",
    "            import json\n",
    "            subset_samples = json.load(f)\n",
    "            subset_samples_tot_idx = {item[1]['total_idx']: \n",
    "                                      {\n",
    "                                          'events': item[1]['events'], \n",
    "                                          'case': item[1]['case']\n",
    "                                      } for item in subset_samples.items()}\n",
    "        \n",
    "        samples.update(subset_samples_tot_idx)\n",
    "    return samples\n",
    "from pathlib import Path          \n",
    "samples = load_all_raw(Path(\"/home/hussain/tactile/data/contact_extraction2/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f205749-f73f-4078-b0a3-d679e0215b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/hussain/tactile/data/contact_extraction1/raw/case.pkl', 'rb') as f:\n",
    "    import pickle\n",
    "    c = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f3dd2a1-5c9d-4cf4-a7aa-d7925b44d44a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mhist(n_ev)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.hist(n_ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e82f30e-aaca-4be8-b9a9-944203922c20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac483fa2-7191-47d2-b69d-bdce041aa5c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m cases, count \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(\u001b[43mc\u001b[49m, return_counts\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mbar(cases, count)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'c' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cases, count = np.unique(c, return_counts=True)\n",
    "plt.bar(cases, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eb363f-32af-4a44-8473-034745d7330e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61723891-7ed4-4d3e-adbf-0b30e924489f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "686"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221f78c5-ba7f-4455-8b1b-2c2bf4d5de0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b92d6b1-fe4b-4106-8c66-6ae80bd29383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "[[0, 0, 0], [0.01234134148078231, 0.012341341480782309, 0], [0.02468268296156462, 0.024682682961564617, 0], [0.03702402451305761, 0.037024024513057606, 0], [0.053033008588991064, 0.05303300858899106, 0], [0.06717514421272203, 0.06717514421272201, 0], [0.08131727983645297, 0.08131727983645295, 0], [0.09545941546018392, 0.09545941546018391, 0], [0.10606601717798213, 0.10606601717798211, 0], [1.0687059397353753e-18, 0.0174532925, 0], [2.1374118794707506e-18, 0.034906585, 0], [3.2061178253293598e-18, 0.0523598776, 0], [4.592425496802574e-18, 0.075, 0], [5.817072295949928e-18, 0.095, 0], [7.04171909509728e-18, 0.115, 0], [8.266365894244634e-18, 0.135, 0], [9.184850993605149e-18, 0.15, 0], [-0.012341341480782309, 0.01234134148078231, 0], [-0.024682682961564617, 0.02468268296156462, 0], [-0.037024024513057606, 0.03702402451305761, 0], [-0.05303300858899106, 0.053033008588991064, 0], [-0.06717514421272201, 0.06717514421272203, 0], [-0.08131727983645295, 0.08131727983645297, 0], [-0.09545941546018391, 0.09545941546018392, 0], [-0.10606601717798211, 0.10606601717798213, 0], [-0.0174532925, 2.1374118794707506e-18, 0], [-0.034906585, 4.274823758941501e-18, 0], [-0.0523598776, 6.4122356506587196e-18, 0], [-0.075, 9.184850993605149e-18, 0], [-0.095, 1.1634144591899856e-17, 0], [-0.115, 1.408343819019456e-17, 0], [-0.135, 1.653273178848927e-17, 0], [-0.15, 1.8369701987210297e-17, 0], [-0.012341341480782312, -0.012341341480782309, 0], [-0.024682682961564624, -0.024682682961564617, 0], [-0.03702402451305762, -0.037024024513057606, 0], [-0.05303300858899108, -0.05303300858899106, 0], [-0.06717514421272203, -0.06717514421272201, 0], [-0.08131727983645298, -0.08131727983645295, 0], [-0.09545941546018394, -0.09545941546018391, 0], [-0.10606601717798216, -0.10606601717798211, 0], [-3.2061178192061255e-18, -0.0174532925, 0], [-6.412235638412251e-18, -0.034906585, 0], [-9.618353475988079e-18, -0.0523598776, 0], [-1.3777276490407722e-17, -0.075, 0], [-1.745121688784978e-17, -0.095, 0], [-2.1125157285291842e-17, -0.115, 0], [-2.4799097682733903e-17, -0.135, 0], [-2.7554552980815445e-17, -0.15, 0], [0.012341341480782307, -0.012341341480782312, 0], [0.024682682961564614, -0.024682682961564624, 0], [0.0370240245130576, -0.03702402451305762, 0], [0.05303300858899105, -0.05303300858899108, 0], [0.067175144212722, -0.06717514421272203, 0], [0.08131727983645295, -0.08131727983645298, 0], [0.0954594154601839, -0.09545941546018394, 0], [0.1060660171779821, -0.10606601717798216, 0], [0.0174532925, -4.274823758941501e-18, 0], [0.034906585, -8.549647517883002e-18, 0], [0.0523598776, -1.2824471301317439e-17, 0], [0.075, -1.8369701987210297e-17, 0], [0.095, -2.3268289183799712e-17, 0], [0.115, -2.816687638038912e-17, 0], [0.135, -3.306546357697854e-17, 0], [0.15, -3.6739403974420595e-17, 0]]\n"
     ]
    }
   ],
   "source": [
    "possible_angle = [0.0174532925, 0.034906585, 0.0523598776, 0.075, 0.095, 0.115, 0.135, 0.15]#\n",
    "N_examples = 9\n",
    "list_of_rotations = [[0, 0, 0]]\n",
    "\n",
    "for i in range(1, N_examples):\n",
    "    theta = i * 2 * np.pi/(N_examples - 1)\n",
    "    for phi in possible_angle:\n",
    "        rx = phi * np.cos(theta)\n",
    "        ry = phi * np.sin(theta)\n",
    "        rotvec = [rx, ry, 0]\n",
    "        list_of_rotations.append(rotvec)\n",
    "\n",
    "print(len(list_of_rotations))\n",
    "print(list_of_rotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "835d5f62-7e30-4568-b52c-ca75438d88aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data.dataset import Subset\n",
    "import torch.nn as nn \n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "#from torch import autograd1\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.utils import normalized_cut\n",
    "from torch_geometric.nn import voxel_grid, max_pool, max_pool_x, graclus, global_mean_pool, GCNConv,  global_mean_pool\n",
    "#from torch_geometric.nn.conv import SplineConv\n",
    "#from torch_geometric.nn.norm import BatchNorm\n",
    "from torch_geometric.data import InMemoryDataset, download_url\n",
    "from collections.abc import Sequence\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import time\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(1, 64)\n",
    "        self.bn1 = torch.nn.BatchNorm1d(64)\n",
    "\n",
    "        self.conv2 = GCNConv(64, 64)\n",
    "        self.bn2 = torch.nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.conv3 = GCNConv(64, 512)\n",
    "        self.bn3 = torch.nn.BatchNorm1d(512) \n",
    "        \n",
    "        self.conv4 = GCNConv(512, 256)\n",
    "        self.bn4 = torch.nn.BatchNorm1d(256)  \n",
    "        \n",
    "        self.conv5 = GCNConv(256, 64)\n",
    "        self.bn5 = torch.nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.conv6 = GCNConv(64, 32)\n",
    "        self.bn6 = torch.nn.BatchNorm1d(32)\n",
    "\n",
    "        self.conv7 = GCNConv(32, 16)\n",
    "        self.bn7 = torch.nn.BatchNorm1d(16)        \n",
    "\n",
    "        self.conv8 = GCNConv(16, 2)\n",
    "        self.bn8 = torch.nn.BatchNorm1d(16)    \n",
    "        \n",
    "\n",
    "        self.fc1 = torch.nn.Linear(16, 16)\n",
    "        self.fc2 = torch.nn.Linear(16, 2)\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        #data.x = F.elu(self.conv1(data.x , data.edge_index , data.edge_attr ))\n",
    "        # print(\"index\", data.x.view(-1,2).shape)\n",
    "        data.x = F.sigmoid(self.conv1(torch.tensor(data.x.view(-1,1), dtype=torch.float32), data.edge_index) )#, data.edge_attr ))\n",
    "        data.x = self.bn1(data.x)\n",
    "\n",
    "\n",
    "        data.x = F.sigmoid(self.conv2(data.x, data.edge_index))\n",
    "        data.x = self.bn2(data.x)\n",
    "\n",
    "\n",
    "        data.x = F.sigmoid(self.conv3(data.x, data.edge_index))\n",
    "        data.x = self.bn3(data.x)\n",
    "\n",
    "        data.x = F.sigmoid(self.conv4(data.x, data.edge_index))\n",
    "        data.x = self.bn4(data.x)\n",
    "\n",
    "        data.x = F.sigmoid(self.conv5(data.x, data.edge_index))\n",
    "        data.x = self.bn5(data.x)\n",
    "\n",
    "        data.x = F.sigmoid(self.conv6(data.x, data.edge_index))\n",
    "        data.x = self.bn6(data.x)\n",
    "\n",
    "        data.x = F.sigmoid(self.conv7(data.x, data.edge_index))\n",
    "        data.x = self.bn7(data.x)\n",
    "\n",
    "        # data.x = F.sigmoid(self.conv8(data.x, data.edge_index))\n",
    "                # 2. Readout layer\n",
    "        x = global_mean_pool(data.x, data.batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        #print(\"abdulrahman2 done\",x.size())\n",
    "\n",
    "        out = F.sigmoid(self.fc2(x))\n",
    "        \n",
    "        # print(\"out\", out)\n",
    "#         out=F.softmax(data.x, dim=1)\n",
    "        return out\n",
    "\n",
    "model=Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f90abf-2caf-4df2-8a8f-8189b443631d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n",
      "Training will start now\n",
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                           | 0/686 [00:00<?, ?it/s]/tmp/ipykernel_28970/2442399191.py:21: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with torch.autograd.detect_anomaly():\n",
      "/tmp/ipykernel_28970/2024586760.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data.x = F.sigmoid(self.conv1(torch.tensor(data.x.view(-1,1), dtype=torch.float32), data.edge_index) )#, data.edge_attr ))\n",
      "100%|█████████████████████████████████| 686/686 [01:52<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss 0.0517  Elapsed time:  112.82031679153442\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 686/686 [01:53<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss 0.0516  Elapsed time:  113.00654673576355\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 686/686 [01:52<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, loss 0.0516  Elapsed time:  112.93154263496399\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 686/686 [01:52<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, loss 0.0516  Elapsed time:  112.91658210754395\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 686/686 [01:52<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, loss 0.0516  Elapsed time:  112.867751121521\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 686/686 [01:52<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, loss 0.0516  Elapsed time:  112.74795341491699\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 686/686 [01:52<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, loss 0.0516  Elapsed time:  112.85572242736816\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 686/686 [01:52<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, loss 0.0516  Elapsed time:  112.786217212677\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 686/686 [01:52<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, loss 0.0516  Elapsed time:  112.88748502731323\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 686/686 [01:52<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, loss 0.0516  Elapsed time:  112.91202163696289\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 686/686 [01:52<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss 0.0516  Elapsed time:  112.82803297042847\n",
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 686/686 [01:52<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, loss 0.0516  Elapsed time:  112.94505643844604\n",
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 686/686 [01:52<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, loss 0.0516  Elapsed time:  112.70003461837769\n",
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████▉              | 393/686 [01:04<00:51,  5.65it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "train_loader = DataLoader(td, batch_size=1, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device\", device)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "i=0\n",
    "iv=0\n",
    "epoch_losses = []\n",
    "epoch_lossesv = []\n",
    "number_of_epoch=20\n",
    "print (\"Training will start now\")\n",
    "for epoch in range(number_of_epoch):\n",
    "    print(\"Epoch\", epoch)\n",
    "    epoch_loss = 0\n",
    "    acc=0\n",
    "    start=time.time()    \n",
    "\n",
    "    for i, data in enumerate(tqdm(train_loader)):\n",
    "        with torch.autograd.detect_anomaly():\n",
    "            data = data.to(device)\n",
    "            #print(data.y)\n",
    "            optimizer.zero_grad()\n",
    "            end_point = model(data) \n",
    "\n",
    "            loss = nn.L1Loss()(end_point.view(-1,2)[0], data.y.view(-1,2)[0])\n",
    "            pred = end_point.max(1)[1]\n",
    "            acc += (pred.eq(data.y).sum().item())/len(data.y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print(\"loss\",loss)\n",
    "            # if i % 10 == 0:\n",
    "            #     print({'epoch': epoch,'batch': i + 1,'loss': loss.item(),'acc': acc})\n",
    "\n",
    "            epoch_loss += loss.detach().item()\n",
    "            i=i+1\n",
    "    epoch_loss /= (i + 1)\n",
    "    acc /= (i + 1)\n",
    "\n",
    "    epoch_lossv = 0\n",
    "\n",
    "\n",
    "    #for iv, datav in enumerate(test_loader):\n",
    "# print(data)\n",
    "#         with autograd.detect_anomaly():\n",
    "        #datav = datav.to(device)\n",
    "        #print(data.y)\n",
    "        #end_pointv = model(datav)\n",
    "        #print(\"bbbbb end_point\",(end_point))    \n",
    "        # print(\"bbbbb data.y\",(data.y.view(-1,2) ))  \n",
    "        # print(\"bbbbb end_point\",(end_point.view(-1,2)[0] ))  \n",
    "\n",
    "        #lossv = nn.L1Loss()(end_pointv.view(-1,2)[0], datav.y.view(-1,2)[0])\n",
    "        \n",
    "\n",
    "        # print(\"loss\",loss)\n",
    "        # if i % 10 == 0:\n",
    "        #     print({'epoch': epoch,'batch': i + 1,'loss': loss.item(),'acc': acc})\n",
    "        \n",
    "        #epoch_lossv += lossv.detach().item()\n",
    "        #iv=iv+1\n",
    "        #pass\n",
    "    #epoch_lossv /= (i + 1)\n",
    "\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "    print('Epoch {}, loss {:.4f}'.format(epoch, epoch_loss), ' Elapsed time: ', end-start)\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    #epoch_lossesv.append(epoch_lossv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f290048-15bb-408d-b6de-fbdd27127ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "34b1c1fd0608eac91ff8ee3b378baa82baa76b865f0fb1b05cc06f1667b6717e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
